\section{Enclosed Composite Lexer Productions}
\label{sect:rewriteGrammar:enclosedComposite}
 The XQuery grammar specifies some constructs enclosed by unique symbols, such as \verb!DirPIConstructor! shown in figure \ref{fig:pragma} These rules often contain tokens that overlap with other terminals, so we would draw benefit from moving the productions to the lexer. However, this means that there will only be generated one token by such a rule, and if a later step in the parser want to extract only parts of the construct, it would have to do so manually. Our solution is to make it possible for lexer productions to emit more than one token. In this way, ambiguities would be solved in the lexer, and the parser would still have access to all terminals it should have.

\begin{figure}[h!]
\begin{verbatim}
DirPIConstructor ::= "<?" PITarget (S DirPIContents)? "?>"
DirPIContents    ::= (Char* - (Char* '?>' Char*))
\end{verbatim}
\label{fig:pragma}
\caption[An enclosed production]{\texttt{DirPIConstructor} is an uniquely enclosed production. \texttt{S} denotes whitespace.}
\end{figure}

In addition to \verb!DirPIConstructor! the grammar specifies the other non-terminals with an enclosed content \verb!Pragma!,  \verb!DirCommentConstructor! (XML comment) and \verb!CDataSection!. \verb!Comment! (XQuery comment) has the special property of being able to be nested, but because it is a terminal itself it does not need to generate more than one token.

\subsection{Emiting More Than One Token Per Production}

As can be seen in figure \ref{fig:nextToken}, by default an ANTLR generated lexer will only emit one token per lexer production. To be able to handle multiple emitions, we introduced a buffer in the lexer out of which the parser input \verb!TokenStream! could fetch tokens. By overriding the methods \verb!nextToken()! and \verb!emit(Token t)! we accomodated for this. 

As seen in figure \ref{fig:emitToken} ,our implemented \verb!emit(Token t)! will put the token \verb!t! in the buffer and set the \verb!token! variable of the lexer to \verb!t!, to block it from emitting unwanted tokens (see \verb!if(token == NULL)! in figure \ref{fig:nextToken}).
\begin{figure}[h!]
\begin{verbatim}
public void emit(Token token){
  this.token = token;
  tokens.add(token);
}
\end{verbatim}
\caption[The overridden \texttt{emit(Token t)}]{The implementation of the overriden method \texttt{emit(Token token)}}
\label{fig:emitToken}
\end{figure}

The \verb!nextToken()! method is modified to pick tokens from the buffer, that is, if there are any there. If there are not, it will ask the lexer to make one as before, before returning the first one generated. This is shown in figure \ref{fig:newNextToken}. To be able to use the token generating capabilities of \verb!emit()! we also introduced a method \verb!prepareSubToken()! which ensures that the token will contain correct information about its position.

\begin{figure}[h!]
\begin{verbatim}
public Token nextToken(){
  if(tokens.size() > 0)
    return tokens.remove(0);
  super.nextToken();
  if(tokens.size()==0 )
    return Token.EOF_TOKEN;
  return tokens.remove(0);
}
\end{verbatim}
\caption[The overridden \texttt{nextToken()}]{The implementation of the overriden method \texttt{nextToken()}}
\label{fig:newNextToken}
\end{figure}


\subsection{PI, Pragma, XMLComment and CDATA Sections}

As previously mentioned, the XML markup features processing instructions, pragmas, comments and CDATA sections contain terminals which allowed content overlap significantly with other terminals. However, these terminals are enclosed in unique symbols, making it possible for us to declare the non-terminal rules which refer to them as lexer productions. And with the subtoken emitting functionality described in the last section, the parser will still be able to distinguish the terminals. 

\begin{figure}[h!]
\begin{verbatim}
DirPIConstructor : {prepareSubToken();}
                   LPISi                 {type=LPISi; emit();}
                   {prepareSubToken();}
                   PiTarget           {type=PiTarget; emit();}
                   (S
                     {prepareSubToken();}
                     d=DirPiContents
                     {if(d!=null){type=DirPiContents; emit();} 
                     } 
                   )?
                   {prepareSubToken();}
                   RPISi                 {type=RPISi; emit();}
                   ;
    fragment LPISi           : '<?';
    fragment DirPiContents   : (
                                 {(input.LA(2)!='>')}?=>
                                 QUESTIONSi 
                                 | ~(NotChar | QUESTIONSi)
                               )*;
    fragment RPISi           : '?>';

\end{verbatim}
\caption[\texttt{DirPIConstructor} emitting subtokens]{The implementation of \texttt{DirPIConstructor} with subtoken emitting capabilities.}
\label{fig:pragmaLEX}
\end{figure}

We implemented \verb!DirPIConstructor! as shown in figure \ref{fig:pragmaLEX}. As explained in section \ref{sect:antlr:lexer} ANTLR will generate a method \verb!mDirPIConstructor! from this production, meaning that all actions described will be performed somewhere within \verb!"predict type"! of figure \ref{fig:nextToken}. There will, however, not be generated any \verb!DirPIConstructor! token because of our overridden \verb!emit(Token t)! The \verb!PiTarget! production is described in figure \ref{fig:pitargetRewritten}.

Because the \verb!DirPIContents! part is optional, the lexer will have to check if it is there before emitting such a token. This rule is as seen in the figure implemented non-greedy with the help of a gated semantic predicate, and will stop matching characters as soon as it sees the end of the processing instruction -- \verb!'?>'!. \verb!S! denotes whitespace and will not be emitted, this is because of the lack of the surrounding \verb!prepareSubToken()! and \verb!emit()!.

\subsection{Nested XQuery Comments}
XQuery allows nested comments, for example:
\begin{verbatim}
(: this is a comment (: this comment is nested :) :)
\end{verbatim}
This is a classic problem in compiler construction, however it can be solved using standard ANTLR syntax, without resorting to custom functions/methods for consuming input and keeping track of nesting. The original EBNF as specified by W3C is as follows:
\begin{verbatim}
Comment ::= "(:" (CommentContents | Comment)* ":)"
\end{verbatim}
At first glance, this seems uncomplicated and straight forward, but this grammar needs to be rewritten to be accepted by an LL parser. A suggestion for a solution to this problem was initially found on the Antlr mailing list\footnote{http://www.antlr.org:8080/pipermail/antlr-interest/2005-July/012967.html}, and we loosly based our implementation on such an approach. This lexer rule will correctly detect and allow nested comments, and hide them from the parser:
\begin{verbatim}   
Comment   : LXQCOMMENTSi 
           ({(input.LA(1)=='(' && input.LA(2)==':')}?Comment 
           | {input.LA(2)!=')'}?=>COLONSi
           | {input.LA(2)!=':'}?=>LPARSi
           | ~(LPARSi | COLONSi | NotChar))*
            RXQCOMMENTSi; {$channel=HIDDEN;}
    fragment LXQCOMMENTSi     : '(:';
    fragment RXQCOMMENTSi     : ':)';
\end{verbatim}
Where the disambiguating semantic predicate on the second line can be understood as "if it looks like a comment, it is a comment". The gated semantic predicates on the third and fourth line guards the production from being greedy, i.e. they hide the posibility of matching a \verb!':'! if it is followed by a \verb!')'!, and \verb!'('! if it is followed by a \verb!':'!. By using \verb!$channel=HIDDEN! ANTLR will put this token in an different virtual channel than the default one, making it invisible for the parser unless explicitly asked for. 

\section{Differentiating NCName and Keywords}
\label{sect:rewritegrammar:keywordNCName}

All 139 keywords and 73 symbols are explicitly defined as tokens, as opposed to inline declared in the non-terminal productions. The main reason for this is that it makes it possible to control when the lexer should and should not try to match these by means of predicates. Another benefit from defining the tokens in the lexer is that error messages is much more readable this way. 

When defined inline ANTLR would just assign any unique name to the tokens, making it hard for humans to understand which token is refered to. The names of the tokens for keywords are just the keyword in capital letters, and with and dashes replaced by underscore, e.g. \verb!BASE_URI : 'base-uri'!. A descriptive name with the suffix \verb!Si! consitutes the token names for symbols, e.g. \verb!ASSIGNSi : ':='!.

As discussed in section \ref{sect:antlr:lexer}, ANTLR will generate a lexer correctly differanciating between explicit and inplicit defined character sequences, in our case this is keywords and \verb!NCName! respectively. It acctually resolves this by ranking the explicit ones over the implicit ones, and surpressing warnings about ambiguousity. This works as the highest ranked alternative will always be chosen. But because we introduced the \verb!TOKENSWITCH! construct from figure \ref{fig:tokenswitch}, these warnings will not be surpressed. The keywords and \verb!NCName! were implemented as alternatives to the \verb!fragment! production \verb!LexLiterals! 

\begin{figure}[h!]
\begin{verbatim}
fragment LexLiterals : n=NCName {
 if(state != State.IN_TAG){
   if($n.getText().equals("all")) 
     this.tokenType=ALL;
   else if($n.getText().equals("any")) 
     this.tokenType=ANY;
   else if($n.getText().equals("ancestor")) 
     this.tokenType=ANCESTOR;
   . . .
   . . .
   else 
     this.tokenType=NCName;
   }
  else
   this.tokenType=NCName;
};
\end{verbatim}
\caption[Differantiating keywords from \texttt{NCName}]{An implementation differantiating keywords from \texttt{NCName}}
\label{fig:lexLitterals}
\end{figure}

The solution was to implement all these tokens as \verb!NCName!, with an action checking if the matched token should be one of the keywords, and in such a case change the type. This is shown in figure \ref{fig:lexLitterals}. The initial check if the lexer is in the state \verb!IN_TAG! will prohibit any keywords from occuring inside a XML tag. This manner of fixing the problem is not a preticular good one, and other solutions will be discussed in chapter \ref{sect:summary:future_work}. The reason was mainly to avoid compiler warnings from ANTLR.

\section{Extra-grammatical Constraints}

As well as the grammatical constraints specified in the EBNF grammar, W3C also specifies some extra-grammatical constrains and grammar notes in \cite{w3c00}. In this section we will present these constraints and how we accommodated for them. 

\subsection{Occurrence Indicators}

The W3C grammar specifies the non-terminal \verb!SequenceType! as follows:
\begin{verbatim}
SequenceType ::= ("empty-sequence" "(" ")")
               | (ItemType OccurrenceIndicator?)
\end{verbatim}
It also specifies this extra-gramatical constraint (\cite{w3c00}, section A.1.2):
\begin{quote}
As written, the grammar in A XQuery Grammar is ambiguous for some forms using the '+' and '*' Kleene operators. The ambiguity is resolved as follows: [\ldots] Any occurrence of '+' and '*', as well as '?', following a sequence type is assumed to be an occurrence indicator. That is, a "+", "*", or "?" immediately following an ItemType must be an OccurrenceIndicator\ldots
\end{quote}

This is a clasical case for a syntactic predicate (section \ref{sect:antlr:syntacticPredicate}), which can force the parser to consider a something that looks like a \verb!OccurrenceIndicator! as a \verb!OccurenceIndicator! and not e.g. a arithmetic operator. The implementation of which can be seen in figure \ref{fig:occurrenceIndicator}. The alternative with \verb!ItemType! had to be split into two more alternatives to rank the one with with the \verb!OccurenceIndicator! over the one without.

\begin{figure}[h!]
\begin{verbatim}
sequenceType : (itemType occurrenceIndicator)=> 
               itemType occurrenceIndicator
             | itemType
             | EMPTY_SEQUENCE LPARSi RPARSi
             ;
\end{verbatim}
\caption[The \texttt{OccurenceIndicator} ambiguity solved]{The \texttt{OccurenceIndicator} ambiguity solved by means of a syntactic predicate}
\label{fig:occurrenceIndicator}
\end{figure}

\subsection{Leading Lone Slash}
The constraint is expressed as follows (\cite{w3c00}, section A.1.2):
\begin{quote}
A single slash may appear either as a complete path expression or as the first part of a path expression in which it is followed by a RelativePathExpr, which can take the form of a NameTest ("*" or a QName). In contexts where operators like "*", "union", etc., can occur, parsers may have difficulty distinguishing operators from NameTests. [\ldots] If the token immediately following a slash is "*" or a keyword, then the slash must be the beginning, but not the entirety, of a PathExpr\ldots
\end{quote}

W3Cs \verb!PathExpr! is expressed like this:
\begin{verbatim}
PathExpr  ::= ("/" RelativePathExpr?)
            | ("//" RelativePathExpr)
            | RelativePathExpr
\end{verbatim}

As with the \verb!occurenceIndicator! we split the alternative with the $?$-kleene operator into two explicit alternatives. And by using a syntactic predicate, the parser will prefer the alternative with the \verb!RelativePathExpr! over the single slash one, as seen in figure \ref{fig:leadingSlash}.
\begin{figure}[h!]
\begin{verbatim}
pathExpr    : (SLASHSi relativePathExpr)=> 
              SLASHSi relativePathExpr
            | SLASHSi
            | DBLSLASHSi relativePathExpr
            | relativePathExpr
            ;
\end{verbatim}
\caption[The \texttt{PathExpr} ambiguity solved]{The \texttt{PathExpr} ambiguity solved by means of a syntactic predicate}
\label{fig:leadingSlash}
\end{figure}

\subsection{Reserved Function Names}
W3C specifies the constraint like this (\cite{w3c00}, section A.1.2):
\begin{quote}
Unprefixed function names spelled the same way as language keywords could make the language harder to recognize. For instance, if(foo) could be taken either as a FunctionCall or as the beginning of an IfExpr. Therefore it is not legal syntax for a user to invoke functions with unprefixed names which match any of the names in [\cite{w3c00}, section] A.3 Reserved Function Names.
\end{quote}

Where "A.3 Reserved Function Names" lists a number of names such as \verb!if!, \verb!text! and \verb!node! (thirteen in total). By using a gated syntactic predicate our parser will not be able to see the alternative for \verb!functionCall! if the name of the function is among the restricted ones as seen in figure \ref{fig:reservedFunction}.

\begin{figure}[h!]
\begin{verbatim}
primaryExpr : literal 
            ...
            | {input.LA(1)!=IF && input.LA(1)!=NODE
             && ... && input.LA(1)!=TEXT}?=>
             functionCall 
            ...
            ;
\end{verbatim}
\caption[The \texttt{PathExpr} ambiguity solved]{The \texttt{PathExpr} ambiguity solved by means of a disambiguating semantic predicate}
\label{fig:reservedFunction}
\end{figure}

\textbf{\LARGE //TODO:} This is actually not a problem for our parser as all the reserved function names are keywords, and a function name must be a \verb!qName!, but the restriction is implemented to prepare for a future version with no reserved keywords.

\subsection{Whitespace Explicit}
In the grammar specification some productions is marked with \verb!ws: explicit!, which have the following explanation (\cite{w3c00}, section A.2.4):
\begin{quote}
/* ws: explicit */ means that the EBNF notation explicitly notates, with S or otherwise, where whitespace characters are allowed. [\ldots] Comments are also not allowed in these productions.
\end{quote} 

The productions with this constraint are mainly those associated with XML markup and those we have turned into lexer rules (section \ref{sect:rewriteGrammar:enclosedComposite}). In the case of the enclosed composite rules we have explicitly specified where whitespace is allowed, as can be seen from the referring of \verb!S! in the \verb!DirPIConstructor! in figure \ref{fig:pragmaLEX}. And because these are defined as terminals they cannot contain comments (which is also terminals).

In the case of the XML markup rules we blocked these from containing whitespace and by not allowing in the states the lexer must be in to process these terminals. However, we have allowed default whitespace handling in the \verb!IN_TAG! state for the sake of simplicity, which leads to the bug of allowing space in the start of a tag. This is reported in section \ref{sect:future:knownBugs}.

\subsection{XML Version}
This constraint is specified as follows (\cite{w3c00}, section A.1.2):
\begin{quote}
An implementation's choice to support the XML 1.0 and XML Names, or XML 1.1 and XML Names 1.1 lexical specification determines the external document from which to obtain the definition for this production[s].[\ldots] Also please note that these external productions follow the whitespace rules of their respective specifications, and not the rules of this specification,
\end{quote}

The productions refered to of interest in our case is \verb!NCName! and \verb!Char!. For both of these we have employed the 1.0 specification, as this is the one in most widespread use. However, at this date our parser yet allows inpropper whitespace in \verb!QName!, that is, tag and attribute names, aswell as inpropper nesting of tags. These violations of the constraint have quite easy fixes and are reported in section \ref{sect:future:knownBugs}.

\subsection{Multiple Match Options}
Which is by W3C specified as follows (\cite{w3c00}, section A.1.2):
\begin{quote}
No single alternative for FTMatchOption can be specified more than once as part of the same FTMatchOptions. For example, if the FTCaseOption "lowercase" is specified, then "uppercase" cannot also be specified as part of the same FTMatchOptions.
\end{quote}

As of yet, our parser does not accomodate this constraint as reported in section \ref{sect:future:knownBugs}.

\section{Reserved Keywords}

\underline{\textbf{\LARGE //TODO:}} dette m\aa flyttes eller skrives om.

A particular feature in XQuery is the lack of reserved keywords. This creates a
series of problems when a lexer based on the verbatim grammar specification from
the W3C is trying to recognize tokens. 

v\aa r parser har enna reserved keywords, flytte dette til future work? \\
\underline{\textbf{\LARGE //ODOT:}} 



