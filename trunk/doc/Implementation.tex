\chapter{Implementation}
\label{chapter:implementation}

The main part of implementing the parser was to rewrite the EBNF provided by W3C in \cite{w3c01} to conform to ANTLR's syntax and semantics. Because of the ambiguous terminals described in section \ref{sect:ambiguousgrammar:ambigTerm} this was not a trivial task, and in the following chapter we will present by which means we solved this. In addition we will present other how we reduced the required parser lookahead, implemented a parser that mangages a language without reserved keywords, how we augmented the grammar to output a correct AST and finally our implementation of scoping and symbol tables.


\input{implementation/AntlrSyntax}
\input{implementation/DiffNCNameKeyword}
\input{implementation/ParserControlled}
\input{implementation/EnclosedComposite}
\input{implementation/ReduceLookahead}
\input{implementation/ReservedKeywords}
\input{implementation/ExtraGrammatical}
\input{implementation/CreateAST}
\input{implementation/ScopingAndSymbol}
\input{implementation/ErrorHandling}
\input{implementation/CoverageTests}


\section{Summary}
In this chapter we have gone through by which means we chose to adapt the W3C
XQuery Full-text specification to ANTLR syntax and semantics. We chose to adapt
the specification over creating our own from scratch because the otherwise risk
of missing out essential latent meaning as well as timely concerns, as
discussed further in section \ref{sect:discussion:adaptW3C}.    

By choosing to implement an "parser controlled state driven" lexer, almost all terminal productions
had to be completly rewritten, and also lead to the introduction of the
\verb!TOKENSWITCH! construct. This could be avoided by implementing e.g. a
"scan-while-parse" type lexer, but such a lexer's corresponding parser would
have been much more complex and would handle a much bigger load than that of
our implementation. A more viable alternative would be the "island grammars"
strategy, but because ANTLR does not support this we rejected this solution. In
section \ref{sect:discussion:designDecisions} we further evaluate our choice of
lexer strategy.

We also implemented enclosed composite lexer productions which removed a great
deal of terminal ambiguities by moving the whole refering non-terminal rule
into the lexer. The container tokens were introduced to lessen the strain on
the parser.

The lexer strategy we have choosen depends on the requiret parser lookahead to be held low. Because of this we employed different means of lowering it such as left factoring and augmenting productions with syntactic predicates. An ideal parser would have $k=1$, but as we will discuss in section \ref{sect:discussion:lookahead}, this is not possible for the current version of XQuery.

W3C specifies some extra-gramatical contraints for XQuery Full-text. Our parser
comply with a majority of these, however, there are still some
unconformities, as discussed in section \ref{sect:future:knownBugs}.  

\underline{\textbf{\LARGE //TODO:}} Litt mer hva vi har gjort, og ikke hva vi har vist i rapporten? Hvis noe er diskuterbart s\aa~ gi en liten teaser p\aa~ diskusjonen og referer til senere kap.

We have described the implementation of AST rewrite rules and operators to have
ANTLR generate a complete AST shaped after these rules and operators. We also
examined several XQuery constructs such as FLWOR and path expressions and how
the AST were to be generated for these.

Further we have detailed the implementation of symbol tables and scoping. We
discovered that it was simple to add inline code in the grammar to extend the
parser with these features, however it may seem like this is affecting
readability and clarity of the grammar. In the next chapters this issue will be
further examined and discussed.
\underline{\textbf{\LARGE //ODOT:}}


As we now have seen how the parser was implemented, in the next chapter we will
se how it performs, in particular with regards to coverage test results, AST
output, and error handling.
